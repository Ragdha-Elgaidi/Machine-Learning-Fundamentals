   - An error function is simply a function that measures how far the current state is from the solution
  -  Maximum likelihood- a model that gives the existing labels in our historical data the highest probability
  -  Cross-Entropy is a way of measuring the difference between two distributions.
  -  A perceptron is a major building block of neural networks. Perceptrons are graphs that have nodes and edges.
  -  The backpropagation algorithm uses the chain rule to find the error with the respect to the weights connecting the input layer to the hidden layer (for a two-layer network).

